{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from keras.utils import get_file\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "import xml.sax\n",
    "\n",
    "import subprocess\n",
    "import mwparserfromhell\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "base_dir = '/home/ubuntu/.keras/datasets/wiki_partitions/'\n",
    "tasks = [base_dir + s for s in os.listdir(base_dir)]\n",
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
    "    \"\"\"Used to handle the XML wiki dump. Copied \n",
    "    directly from the book and only edited self._books (from self._movies)\"\"\"\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._books = []\n",
    "        self._curent_tag = None\n",
    "\n",
    "    def characters(self, content):\n",
    "        if self._curent_tag:\n",
    "            self._buffer.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name in ('title', 'text'):\n",
    "            self._curent_tag = name\n",
    "            self._buffer = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == self._curent_tag:\n",
    "            self._values[name] = ' '.join(self._buffer)\n",
    "\n",
    "        if name == 'page':\n",
    "            book = process_article(**self._values)\n",
    "            if book:\n",
    "                self._books.append(book)\n",
    "\n",
    "def process_article(title, text, return_wikicode = False):\n",
    "    \"\"\"Process a wikipedia article looking for books\"\"\"\n",
    "    # Create a parsing object\n",
    "    wikicode = mwparserfromhell.parse(text)\n",
    "    if return_wikicode:\n",
    "        return wikicode\n",
    "    \n",
    "    # Search through templates for the book template\n",
    "    book = next((template for template in wikicode.filter_templates() \n",
    "                 if template.name.strip().lower() in ['infobox book']), None)\n",
    "    if book:\n",
    "        properties = {param.name.strip_code().strip(): param.value.strip_code().strip() \n",
    "                      for param in book.params\n",
    "                      if param.value.strip_code().strip()\n",
    "                     }\n",
    "        links = [x.title.strip_code().strip() for x in wikicode.filter_wikilinks()]\n",
    "        return (title, properties, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_13.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_14.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_5.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_3.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_7.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_4.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_1.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_8.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_9.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_16.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_6.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_12.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_15.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_11.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_2.bz2',\n",
       " '/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_10.bz2']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = tasks[6]\n",
    "\n",
    "# Object for handling xml\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "\n",
    "for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                             stdin = open(data_path), stdout = subprocess.PIPE).stdout):\n",
    "    try:\n",
    "        parser.feed(line)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    if len(handler._books) > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_1.bz2'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(handler._books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def service(data_path):\n",
    "    # Object for handling xml\n",
    "    handler = WikiXmlHandler()\n",
    "\n",
    "    # Parsing object\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(handler)\n",
    "    \n",
    "    for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                             stdin = open(data_path), stdout = subprocess.PIPE).stdout):\n",
    "        try:\n",
    "            parser.feed(line)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        if handler._books:\n",
    "            return handler._values\n",
    "    \n",
    "    return handler._values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "threads = [Thread(target = service_function, kwargs={'data_path': path}) for path in tasks]\n",
    "[t.start() for t in threads]\n",
    "[t.join() for t in threads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'title': 'Animalia (book)',\n",
       "  'text': \"{{Use dmy dates|date=June 2013}} \\n {{Infobox book| < !-- See Wikipedia:WikiProject_Novels or Wikipedia:WikiProject_Books -- > \\n | name          = '''Animalia''' \\n | image         = Animalia (book cover).jpg \\n | caption       =  \\n | alt           = Book cover: a larger picture framed by smaller pictures, all of which contain different animals, and title with author at the top \\n | author        = [[Graeme Base]] \\n | illustrator   = Graeme Base \\n | country       = Australia \\n | language      = English  \\n | genre         = [[Picture books]] \\n | publisher     = [[Harcourt Brace Jovanovich]] \\n | release_date  = 1986 \\n | pages         = 32 \\n | isbn          = 0-810-91868-4 \\n | oclc          =  \\n }} \\n < !--{{Infobox publication|image=Animalia.jpg|caption=Book cover}}-- > \\n '''''Animalia''''' is an illustrated [[Children's literature|children's book]] by [[Graeme Base]]. It was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th anniversary edition in 2012. Over three million copies have been sold. < ref > {{cite web|last=Puffin Books|title=Animalia 25th Anniversary Edition|url=http://www.puffin.com.au/products/9780670076673/animalia-25th-anniversary-edition|accessdate=7 June 2013}} < /ref >    A special numbered and signed anniversary edition was also published in 1996, with an embossed gold jacket. < ref > {{cite web|last=ABE Books|title=Animalia (Numbered and Signed anniversary edition)|url=http://www.abebooks.com/Animalia-Numbered-Signed-Anniversary-Edition-Base/3201558151/bd|accessdate=8 June 2013}} < /ref > \\n \\n ==Synopsis== \\n ''Animalia'' is an [[alliteration|alliterative]] [[alphabet]] book and contains twenty-six illustrations, one for each letter of the alphabet. Each illustration features an animal from the animal kingdom (A is for [[alligator]], B is for [[butterfly]], etc.) along with a short poem utilizing the letter of the page for many of the words. The illustrations contain many other objects beginning with that letter that the reader can try to identify. As an additional challenge, the author has hidden a picture of himself as a child in every picture. \\n \\n ==Related products== \\n Julia MacRae Books published an ''Animalia'' [[colouring book]] in 2008. < ref > {{cite web|last=Penguin Books |title=Animalia Colouring Book |url=http://www.penguin.com.au/products/9781405904674/animalia-colouring-book |accessdate=8 June 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20131002205038/http://www.penguin.com.au/products/9781405904674/animalia-colouring-book |archivedate=2 October 2013 }} < /ref >    [[Abrams Books|H. N. Abrams]] also published a wall calendar colouring book version for children the same year. < ref > {{cite web|last=LibraryThing.com|title=Animalia 2008 Coloring Calendar|url=http://www.librarything.com/work/6090521|accessdate=8 June 2013}} < /ref > \\n \\n H. N. Abrams published ''The Animalia Wall Frieze'', a fold-out over 26 feet in length, in which the author created new riddles for each letter. < ref > {{cite web|last=BookFinder.com|title=The Animalia Wall Frieze|url=http://www.bookfinder.com/dir/i/The_Animalia_Wall_Frieze/0810924757/|accessdate=8 June 2013}} < /ref > \\n \\n The Great American Puzzle Factory created a 300-piece jigsaw puzzle based on the book's cover. < ref > {{cite web|last=Amazon.com|title=Animalia 300-piece jigsaw puzzle|url=https://www.amazon.com/Animalia-Graeme-Piece-Jigsaw-Puzzle/sim/B000R2ZUCE/2|accessdate=8 June 2013}} < /ref > \\n \\n ==Adaptations== \\n A [[Animalia (TV series)|television series]] was also created, based on the book, which airs in the United States, Australia, Canada, the United Kingdom, Norway and [[Venezuela]]. It also airs on [[Minimax (TV channel)|Minimax]] for the [[Czech Republic]] and [[Slovakia]]. And recently in [[Greece]] on the channel [[ET1 (Greece)|ET1]]. The [[Australian Children's Television Foundation]] released a teaching resource DVD-ROM in 2011 to accompany the TV series with teaching aids for classroom use. < ref > {{cite web|last=Curriculum Press |title=Animalia - Primary teaching resource |url=http://www.curriculumpress.edu.au/main/goproduct/13167 |accessdate=7 June 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20130503092444/http://www.curriculumpress.edu.au/main/goproduct/13167 |archivedate=3 May 2013 }} < /ref > \\n \\n In 2010, The Base Factory and AppBooks released Animalia as an application for [[iPad]] and [[iPhone]]/[[iPod Touch]]. < ref > {{cite web|last=MyBookCorner.com.au|title=Animalia - Anniversary Edition|url=http://www.mybookcorner.com.au/apps/611-animalia-anniversary-edition|accessdate=7 June 2013}} < /ref > \\n \\n ==Awards== \\n ''Animalia'' won the Young Australian's Best Book Award in 1987 for Best Picture Story Book. < ref > {{cite web|last=Yabba.org|title=Award Winners - 1986 through 2011|url=http://yabba.org.au/award-winners-1986-through-2011/|accessdate=8 June 2013}} < /ref > \\n \\n The [[Children's Book Council of Australia]] designated ''Animalia'' a 1987 [[Children's Book of the Year Award: Picture Book|Picture Book of the Year]]: Honour Book. < ref > {{cite web|last=The Children's Book Council of Australia |title=Winners and Commended Books 1980 - 1989 |url=http://cbca.org.au/8089.htm |accessdate=8 June 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20141216043453/http://cbca.org.au/8089.htm |archivedate=16 December 2014 }} < /ref > \\n \\n Kid's Own Australian Literature Awards named ''Animalia'' the 1988 Picture Book Winner. < ref > {{cite web|last=KOALA New South Wales |title=Complete list of KOALA winners 1987 to 2012 |url=http://www.koalansw.org.au/storage/Complete%20list%20winners%201987%20to%202012.pdf |accessdate=8 June 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20130409162703/http://www.koalansw.org.au/storage/Complete%20list%20winners%201987%20to%202012.pdf |archivedate=9 April 2013 }} < /ref > \\n \\n ==References== \\n {{Reflist}} \\n \\n ==External links== \\n {{Portal |Children's literature}} \\n * [http://www.graemebase.com Graeme Base's official website] \\n * [http://www.animalia.tv Animalia The Television Series official website] \\n * [http://www.thelittlebigbookclub.com.au/sites/thelittlebigbookclub.com.au/files/files/title_resource/learning_time_2-3_years_july2011.pdf A Learning Time activity guide] for ''Animalia'' created by The Little Big Book Club \\n \\n {{Graeme Base}} \\n \\n {{DEFAULTSORT:Animalia (Book)}} \\n [[Category:Alphabet books]] \\n [[Category:1986 children's books]] \\n [[Category:Picture books by Graeme Base]] \\n [[Category:Puzzle books]] \\n [[Category:Australian children's books]]\"},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "pool = ThreadPool(16)\n",
    "results = pool.map(service, tasks)\n",
    "pool.close()\n",
    "pool.join()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_13.bz2/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_14.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_5.bz2\n",
      "\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_3.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_7.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_4.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_1.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_8.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_9.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_16.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_6.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_12.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_15.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_11.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_2.bz2\n",
      "/home/ubuntu/.keras/datasets/wiki_partitions/enwiki-20180901-pages-articles.xml_10.bz2\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures.thread import ThreadPoolExecutor\n",
    "x = []\n",
    "with ThreadPoolExecutor(max_workers = 16) as executor:\n",
    "    for path in tasks:\n",
    "        x.append(executor.submit(service, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
