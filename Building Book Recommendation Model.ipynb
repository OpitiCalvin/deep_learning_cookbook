{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape, Dense\n",
    "from keras.layers.merge import Dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36552"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = []\n",
    "\n",
    "with open('/data/books.ndjson') as fin:\n",
    "    for line in fin.readlines():\n",
    "        # Use loads because this is an object\n",
    "        books.append(json.loads(line))\n",
    "        \n",
    "len(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hardcover', 7603),\n",
       " ('Paperback', 7451),\n",
       " ('Wikipedia:WikiProject Books', 6081),\n",
       " ('Wikipedia:WikiProject Novels', 6053),\n",
       " ('English language', 4259),\n",
       " ('The New York Times', 3909),\n",
       " ('United States', 3366),\n",
       " ('Science fiction', 3105),\n",
       " ('science fiction', 2648),\n",
       " ('Publishers Weekly', 2350)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "\n",
    "for book in books:\n",
    "    link_counts.update(book[2])\n",
    "    \n",
    "link_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Blade Runner 2: The Edge of Human'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Blade Runner 2: < br > The Edge of Human',\n",
       " 'author': 'K. W. Jeter',\n",
       " 'language': 'English',\n",
       " 'country': 'United States',\n",
       " 'genre': 'Science fiction',\n",
       " 'isbn': '0-553-09979-5',\n",
       " '1': '< !-- See Wikipedia:WikiProject_Novels or Wikipedia:WikiProject_Books -- >',\n",
       " 'image': 'File:Blade Runner 2 The Edge of Human KW Jeter cover.jpg',\n",
       " 'series': 'Blade Runner',\n",
       " 'release_date': 'October 1, 1995',\n",
       " 'media_type': 'Print (Hardcover, Paperback)',\n",
       " 'pages': '340',\n",
       " 'dewey': '813/.54 20',\n",
       " 'congress': 'PS3560.E85 B58 1995',\n",
       " 'oclc': '32548543',\n",
       " 'preceded_by': 'Do Androids Dream of Electric Sheep?',\n",
       " 'followed_by': 'Replicant Night',\n",
       " 'caption': 'Cover of the first edition'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38357 links with more than 4 occurrences.\n",
      "There are 36552 books.\n"
     ]
    }
   ],
   "source": [
    "top_links = [link for link, c in link_counts.items() if c >= 5]\n",
    "\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "idx_to_link = {idx: link for link, idx in link_to_idx.items()}\n",
    "\n",
    "book_to_idx = {book[0]: idx for idx, book in enumerate(books)}\n",
    "idx_to_book = {idx: book for book, idx in book_to_idx.items()}\n",
    "\n",
    "print(f'There are {len(top_links)} links with more than 4 occurrences.')\n",
    "print(f'There are {len(book_to_idx)} books.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for book in books:\n",
    "    pairs.extend((link_to_idx[link], \n",
    "                  book_to_idx[book[0]]) for link in book[2] if link in top_links)\n",
    "    \n",
    "len(pairs)\n",
    "pairs[-10]\n",
    "\n",
    "pairs_set = set(pairs)\n",
    "len(pairs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[1500]\n",
    "idx_to_link[pairs[1500][0]]\n",
    "idx_to_book[pairs[1500][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[2100]\n",
    "idx_to_link[pairs[2100][0]]\n",
    "idx_to_book[pairs[2100][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_embedding_model(embedding_size=50):\n",
    "    # Each input is (batch_size, 1)\n",
    "    link = Input(name = 'link', shape = [1])\n",
    "    book = Input(name = 'book', shape = [1])\n",
    "    \n",
    "    # Embed the link\n",
    "    link_embedding = Embedding(name = 'link_embedding',\n",
    "                               input_dim = len(top_links),\n",
    "                               output_dim = embedding_size)(link)\n",
    "    \n",
    "    # Reshape to be (batch_size, embedding_size)\n",
    "    link_embedding = Reshape([embedding_size])(link_embedding)\n",
    "    \n",
    "    # Embed the book\n",
    "    book_embedding = Embedding(name = 'book_embedding',\n",
    "                               input_dim = len(book_to_idx),\n",
    "                               output_dim = embedding_size)(book)\n",
    "    \n",
    "    # Reshape to be (batch_size, embedding_size)\n",
    "    book_embedding = Reshape([embedding_size])(book_embedding)\n",
    "    \n",
    "    # Take the dot product of the second axes (the embedding)\n",
    "    dot = Dot(name = 'dot_product', normalize = True, \n",
    "              axes = 1)([link_embedding, book_embedding])\n",
    "    output = Dense(1, activation = 'sigmoid', name = 'output')(dot)\n",
    "    # Create the model and compile\n",
    "    model = Model(inputs = [link, book], outputs = [output])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = book_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(pairs, num_pos=1, neg_ratio=3):\n",
    "    \"\"\"Generate batches of positive and negative samples\"\"\"\n",
    "    batch_size = num_pos * (1 + neg_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        # Sample random positive samples\n",
    "        for idx, (link_id, book_id) in enumerate(random.sample(pairs, num_pos)):\n",
    "            batch[idx, :] = (link_id, book_id, 1)\n",
    "            \n",
    "        idx += 1\n",
    "        while idx < batch_size:\n",
    "    \n",
    "            # Sample a random movie and a random link\n",
    "            book_id = random.randrange(len(book_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            \n",
    "            # Check to make sure this is not a positive example\n",
    "            if (book_id, link_id) not in pairs_set:\n",
    "                # This is a negative sample\n",
    "                batch[idx, :] = (book_id, link_id, 0)\n",
    "                idx += 1\n",
    "                \n",
    "        np.random.shuffle(batch)\n",
    "        \n",
    "        # Inputs to model and output\n",
    "        yield {'link': batch[:, 0], 'book': batch[:, 1]}, batch[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(batcher(pairs, num_pos = 5, neg_ratio = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos_samples = 256\n",
    "\n",
    "train_gen = batcher(pairs, num_pos_samples, 4)\n",
    "valid_gen = batcher(pairs, num_pos_samples, 4)\n",
    "\n",
    "model.fit_generator(\n",
    "        # Set the generator\n",
    "        train_gen,\n",
    "        epochs = 15,\n",
    "        # Batches per epoch\n",
    "        steps_per_epoch = len(pairs) // num_pos_samples,\n",
    "        validation_data = valid_gen,\n",
    "        # Validation batches per epoch\n",
    "        validation_steps = (len(pairs) // num_pos_samples) // 10,\n",
    "        verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_link_counts = list(map(lambda x: (x[0], len(x[2])), books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_link_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
