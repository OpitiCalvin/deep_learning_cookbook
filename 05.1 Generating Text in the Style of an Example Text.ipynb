{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers, models, utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_everything():\n",
    "    import tensorflow as tf\n",
    "    %reset -f in out dhist\n",
    "    tf.reset_default_graph()\n",
    "    K.set_session(tf.InteractiveSession())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for our networks.  We keep these deliberately small to reduce training time.\n",
    "\n",
    "VOCAB_SIZE = 250000\n",
    "EMBEDDING_SIZE = 100\n",
    "MAX_DOC_LEN = 128\n",
    "MIN_DOC_LEN = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded. File size: 0.117212775 GB\n"
     ]
    }
   ],
   "source": [
    "def extract_stackexchange(filename, limit=1000000):\n",
    "    json_file = filename + 'limit=%s.json' % limit\n",
    "\n",
    "    rows = []\n",
    "    for i, line in enumerate(os.popen('7z x -so \"%s\" Posts.xml' % filename)):\n",
    "        line = str(line)\n",
    "        if not line.startswith('  <row'):\n",
    "            continue\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print('\\r%05d/%05d' % (i, limit), end='', flush=True)\n",
    "\n",
    "        parts = line[6:-5].split('\"')\n",
    "        record = {}\n",
    "        for i in range(0, len(parts), 2):\n",
    "            k = parts[i].replace('=', '').strip()\n",
    "            v = parts[i+1].strip()\n",
    "            record[k] = v\n",
    "        rows.append(record)\n",
    "        \n",
    "        if len(rows) > limit:\n",
    "            break\n",
    "    \n",
    "    with open(json_file, 'w') as fout:\n",
    "        json.dump(rows, fout)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "data_path = '/home/ubuntu/.keras/datasets/travel.stackexchange.com.7zlimit=1000000.json'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    xml_7z = utils.get_file(\n",
    "        fname='travel.stackexchange.com.7z',\n",
    "        origin='https://ia800107.us.archive.org/27/items/stackexchange/travel.stackexchange.com.7z',\n",
    "    )\n",
    "    rows = extract_stackexchange(xml_7z)\n",
    "else:\n",
    "    print(\"Already downloaded. File size:\", os.stat(data_path).st_size / 1e9, 'GB')\n",
    "    with open(data_path, 'r') as fin:\n",
    "        # Use load with a file (loads with json)\n",
    "        rows = json.load(fin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Now that we have extracted our data, let's clean it up and take a look at what we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': '2',\n",
       " 'PostTypeId': '1',\n",
       " 'CreationDate': '2011-06-21T20:22:33.760',\n",
       " 'Score': '36',\n",
       " 'ViewCount': '1876',\n",
       " 'Body': \"&lt;p&gt;This was one of our definition questions, but also one that interests me personally: How can I find a guide that will take me safely through the Amazon jungle? I'd love to explore the Amazon but would not attempt it without a guide, at least not the first time. And I'd prefer a guide that wasn't going to ambush me or anything. :P&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't want to go anywhere &quot;touristy&quot;.  Start and end points are open, but the trip should take me places where I am not likely to see other travelers/tourists and where I will definitely require a good guide in order to be safe.&lt;/p&gt;&#xA;\",\n",
       " 'OwnerUserId': '13',\n",
       " 'LastEditorUserId': '51577',\n",
       " 'LastEditDate': '2018-08-14T16:23:48.240',\n",
       " 'LastActivityDate': '2018-08-26T00:04:13.520',\n",
       " 'Title': 'How can I find a guide that will take me safely through the Amazon jungle?',\n",
       " 'Tags': '&lt;guides&gt;&lt;extreme-tourism&gt;&lt;amazon-river&gt;&lt;amazon-jungle&gt;',\n",
       " 'AnswerCount': '8',\n",
       " 'CommentCount': '4',\n",
       " 'FavoriteCount': '5'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>...</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>393</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;p&amp;gt;My fianc√©e and I are looking for a go...</td>\n",
       "      <td>2013-02-25T23:52:47.953</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:19:34.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-24T14:52:14.760</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;caribbean&amp;gt;&amp;lt;cruising&amp;gt;&amp;lt;vacations...</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;p&amp;gt;This was one of our definition questi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:22:33.760</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-26T00:04:13.520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>&amp;lt;guides&amp;gt;&amp;lt;extreme-tourism&amp;gt;&amp;lt;amazo...</td>\n",
       "      <td>How can I find a guide that will take me safel...</td>\n",
       "      <td>1876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;lt;p&amp;gt;One way would be to go through an Adv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:28.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-06-21T20:24:28.080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;p&amp;gt;Singapore Airlines has an all-busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:57.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-09T09:55:22.743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;loyalty-programs&amp;gt;&amp;lt;routes&amp;gt;&amp;lt;ewr&amp;...</td>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>770</td>\n",
       "      <td>5</td>\n",
       "      <td>&amp;lt;p&amp;gt;Another definition question that inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:25:56.787</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-12T20:49:08.110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>&amp;lt;romania&amp;gt;&amp;lt;transportation&amp;gt;</td>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>418.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AcceptedAnswerId AnswerCount  \\\n",
       "Id                                \n",
       "1               393           4   \n",
       "2               NaN           8   \n",
       "3               NaN         NaN   \n",
       "4               NaN           1   \n",
       "5               770           5   \n",
       "\n",
       "                                                 Body  \\\n",
       "Id                                                      \n",
       "1   &lt;p&gt;My fianc√©e and I are looking for a go...   \n",
       "2   &lt;p&gt;This was one of our definition questi...   \n",
       "3   &lt;p&gt;One way would be to go through an Adv...   \n",
       "4   &lt;p&gt;Singapore Airlines has an all-busines...   \n",
       "5   &lt;p&gt;Another definition question that inte...   \n",
       "\n",
       "                 ClosedDate CommentCount CommunityOwnedDate  \\\n",
       "Id                                                            \n",
       "1   2013-02-25T23:52:47.953            4                NaN   \n",
       "2                       NaN            4                NaN   \n",
       "3                       NaN            2                NaN   \n",
       "4                       NaN            1                NaN   \n",
       "5                       NaN            0                NaN   \n",
       "\n",
       "               CreationDate FavoriteCount  Id         LastActivityDate  \\\n",
       "Id                                                                       \n",
       "1   2011-06-21T20:19:34.730           NaN   1  2012-05-24T14:52:14.760   \n",
       "2   2011-06-21T20:22:33.760             5   2  2018-08-26T00:04:13.520   \n",
       "3   2011-06-21T20:24:28.080           NaN   3  2011-06-21T20:24:28.080   \n",
       "4   2011-06-21T20:24:57.160           NaN   4  2013-01-09T09:55:22.743   \n",
       "5   2011-06-21T20:25:56.787             2   5  2012-10-12T20:49:08.110   \n",
       "\n",
       "      ...    LastEditorDisplayName LastEditorUserId OwnerDisplayName  \\\n",
       "Id    ...                                                              \n",
       "1     ...                      NaN              101              NaN   \n",
       "2     ...                      NaN            51577              NaN   \n",
       "3     ...                      NaN              NaN              NaN   \n",
       "4     ...                      NaN              693              NaN   \n",
       "5     ...                      NaN              101              NaN   \n",
       "\n",
       "   OwnerUserId ParentId PostTypeId  Score  \\\n",
       "Id                                          \n",
       "1            9      NaN          1      8   \n",
       "2           13      NaN          1     36   \n",
       "3            9        2          2     14   \n",
       "4           24      NaN          1      8   \n",
       "5           13      NaN          1     13   \n",
       "\n",
       "                                                 Tags  \\\n",
       "Id                                                      \n",
       "1   &lt;caribbean&gt;&lt;cruising&gt;&lt;vacations...   \n",
       "2   &lt;guides&gt;&lt;extreme-tourism&gt;&lt;amazo...   \n",
       "3                                                       \n",
       "4   &lt;loyalty-programs&gt;&lt;routes&gt;&lt;ewr&...   \n",
       "5               &lt;romania&gt;&lt;transportation&gt;   \n",
       "\n",
       "                                                Title ViewCount  \n",
       "Id                                                               \n",
       "1        What are some Caribbean cruises for October?     443.0  \n",
       "2   How can I find a guide that will take me safel...    1876.0  \n",
       "3                                                           NaN  \n",
       "4   Does Singapore Airlines offer any reward seats...     249.0  \n",
       "5   What is the easiest transportation to use thro...     418.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(rows)    \n",
    "df = df.set_index('Id', drop=False)\n",
    "df['Title'] = df['Title'].fillna('').astype('str')\n",
    "df['Tags'] = df['Tags'].fillna('').astype('str')\n",
    "df['Body'] = df['Body'].fillna('').astype('str')\n",
    "df['Id'] = df['Id'].astype('int')\n",
    "df['PostTypeId'] = df['PostTypeId'].astype('int')\n",
    "df['ViewCount'] = df['ViewCount'].astype('float')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do I need a US visa to transit (or layover) through an American airport?',\n",
       " 'How to get from Nice to Monaco by public transport?',\n",
       " 'Should my first trip be to the country which issued my Schengen Visa?',\n",
       " 'Can I use Google Maps traffic information to estimate driving time for a specific date/time?',\n",
       " 'Are aerosol cans allowed and safe, in checked luggage?',\n",
       " 'How to track my UK Visa Application Status?',\n",
       " \"When applying for an Indian Passport, how do I know if I'm in the ECR or non-ECR category?\",\n",
       " 'Are battery packs allowed in hand luggage?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df['ViewCount'] > 250000]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(df['Body'] + df['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87956"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87956"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF/IDF Values\n",
    "\n",
    "total_count = sum(tokenizer.word_counts.values())\n",
    "idf = { k: np.log(total_count/v) for (k,v) in tokenizer.word_counts.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 3.603566009125561)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idf.keys())[10], list(idf.values())[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('gt', 2.8184622225006084), (\"'low'\", 16.670909155734705))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idf = sorted(idf.items(), key = lambda x: x[1])\n",
    "sorted_idf[0], sorted_idf[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/deep-learning-cookbook/glove.6B.100d.txt\n",
      "347119616/347116733 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:15: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained word2vec embeddings\n",
    "\n",
    "import gensim\n",
    "\n",
    "glove_100d = utils.get_file(\n",
    "    fname='glove.6B.100d.txt',\n",
    "    origin='https://storage.googleapis.com/deep-learning-cookbook/glove.6B.100d.txt',\n",
    ")\n",
    "\n",
    "w2v_100d = glove_100d + '.w2v'\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_100d, w2v_100d)\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(w2v_100d)\n",
    "\n",
    "w2v_weights = np.zeros((VOCAB_SIZE, w2v_model.syn0.shape[1]))\n",
    "idf_weights = np.zeros((VOCAB_SIZE, 1))\n",
    "\n",
    "for k, v in tokenizer.word_index.items():\n",
    "    if v >= VOCAB_SIZE:\n",
    "        continue\n",
    "    \n",
    "    if k in w2v_model:\n",
    "        w2v_weights[v] = w2v_model[k]\n",
    "    \n",
    "    idf_weights[v] = idf[k]\n",
    "    \n",
    "del w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_tokens'] = tokenizer.texts_to_sequences(df['Title'])\n",
    "df['body_tokens'] = tokenizer.texts_to_sequences(df['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>...</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>body_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>393</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;p&amp;gt;My fianc√©e and I are looking for a go...</td>\n",
       "      <td>2013-02-25T23:52:47.953</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:19:34.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-24T14:52:14.760</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;caribbean&amp;gt;&amp;lt;cruising&amp;gt;&amp;lt;vacations...</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>443.0</td>\n",
       "      <td>[67, 20, 62, 2287, 2935, 15, 1209]</td>\n",
       "      <td>[2, 4, 1, 37, 9705, 9, 12, 20, 386, 15, 6, 168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;p&amp;gt;This was one of our definition questi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:22:33.760</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-26T00:04:13.520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>&amp;lt;guides&amp;gt;&amp;lt;extreme-tourism&amp;gt;&amp;lt;amazo...</td>\n",
       "      <td>How can I find a guide that will take me safel...</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>[91, 33, 12, 120, 6, 698, 16, 36, 105, 96, 271...</td>\n",
       "      <td>[2, 4, 1, 32, 59, 55, 13, 346, 2593, 113, 34, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;lt;p&amp;gt;One way would be to go through an Adv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:28.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-06-21T20:24:28.080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 4, 1, 55, 110, 54, 19, 7, 87, 111, 43, 313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;p&amp;gt;Singapore Airlines has an all-busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:57.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-09T09:55:22.743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;loyalty-programs&amp;gt;&amp;lt;routes&amp;gt;&amp;lt;ewr&amp;...</td>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>249.0</td>\n",
       "      <td>[122, 739, 183, 514, 61, 4943, 609, 18, 97, 31...</td>\n",
       "      <td>[2, 4, 1, 739, 183, 79, 43, 66, 312, 269, 75, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>770</td>\n",
       "      <td>5</td>\n",
       "      <td>&amp;lt;p&amp;gt;Another definition question that inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:25:56.787</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-12T20:49:08.110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>&amp;lt;romania&amp;gt;&amp;lt;transportation&amp;gt;</td>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>[67, 14, 5, 2068, 840, 7, 103, 2166, 1471, 15,...</td>\n",
       "      <td>[2, 4, 1, 192, 2593, 176, 16, 1080, 96, 59, 67...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AcceptedAnswerId AnswerCount  \\\n",
       "Id                                \n",
       "1               393           4   \n",
       "2               NaN           8   \n",
       "3               NaN         NaN   \n",
       "4               NaN           1   \n",
       "5               770           5   \n",
       "\n",
       "                                                 Body  \\\n",
       "Id                                                      \n",
       "1   &lt;p&gt;My fianc√©e and I are looking for a go...   \n",
       "2   &lt;p&gt;This was one of our definition questi...   \n",
       "3   &lt;p&gt;One way would be to go through an Adv...   \n",
       "4   &lt;p&gt;Singapore Airlines has an all-busines...   \n",
       "5   &lt;p&gt;Another definition question that inte...   \n",
       "\n",
       "                 ClosedDate CommentCount CommunityOwnedDate  \\\n",
       "Id                                                            \n",
       "1   2013-02-25T23:52:47.953            4                NaN   \n",
       "2                       NaN            4                NaN   \n",
       "3                       NaN            2                NaN   \n",
       "4                       NaN            1                NaN   \n",
       "5                       NaN            0                NaN   \n",
       "\n",
       "               CreationDate FavoriteCount  Id         LastActivityDate  \\\n",
       "Id                                                                       \n",
       "1   2011-06-21T20:19:34.730           NaN   1  2012-05-24T14:52:14.760   \n",
       "2   2011-06-21T20:22:33.760             5   2  2018-08-26T00:04:13.520   \n",
       "3   2011-06-21T20:24:28.080           NaN   3  2011-06-21T20:24:28.080   \n",
       "4   2011-06-21T20:24:57.160           NaN   4  2013-01-09T09:55:22.743   \n",
       "5   2011-06-21T20:25:56.787             2   5  2012-10-12T20:49:08.110   \n",
       "\n",
       "                          ...                         OwnerDisplayName  \\\n",
       "Id                        ...                                            \n",
       "1                         ...                                      NaN   \n",
       "2                         ...                                      NaN   \n",
       "3                         ...                                      NaN   \n",
       "4                         ...                                      NaN   \n",
       "5                         ...                                      NaN   \n",
       "\n",
       "   OwnerUserId ParentId PostTypeId Score  \\\n",
       "Id                                         \n",
       "1            9      NaN          1     8   \n",
       "2           13      NaN          1    36   \n",
       "3            9        2          2    14   \n",
       "4           24      NaN          1     8   \n",
       "5           13      NaN          1    13   \n",
       "\n",
       "                                                 Tags  \\\n",
       "Id                                                      \n",
       "1   &lt;caribbean&gt;&lt;cruising&gt;&lt;vacations...   \n",
       "2   &lt;guides&gt;&lt;extreme-tourism&gt;&lt;amazo...   \n",
       "3                                                       \n",
       "4   &lt;loyalty-programs&gt;&lt;routes&gt;&lt;ewr&...   \n",
       "5               &lt;romania&gt;&lt;transportation&gt;   \n",
       "\n",
       "                                                Title ViewCount  \\\n",
       "Id                                                                \n",
       "1        What are some Caribbean cruises for October?     443.0   \n",
       "2   How can I find a guide that will take me safel...    1876.0   \n",
       "3                                                           NaN   \n",
       "4   Does Singapore Airlines offer any reward seats...     249.0   \n",
       "5   What is the easiest transportation to use thro...     418.0   \n",
       "\n",
       "                                         title_tokens  \\\n",
       "Id                                                      \n",
       "1                  [67, 20, 62, 2287, 2935, 15, 1209]   \n",
       "2   [91, 33, 12, 120, 6, 698, 16, 36, 105, 96, 271...   \n",
       "3                                                  []   \n",
       "4   [122, 739, 183, 514, 61, 4943, 609, 18, 97, 31...   \n",
       "5   [67, 14, 5, 2068, 840, 7, 103, 2166, 1471, 15,...   \n",
       "\n",
       "                                          body_tokens  \n",
       "Id                                                     \n",
       "1   [2, 4, 1, 37, 9705, 9, 12, 20, 386, 15, 6, 168...  \n",
       "2   [2, 4, 1, 32, 59, 55, 13, 346, 2593, 113, 34, ...  \n",
       "3   [2, 4, 1, 55, 110, 54, 19, 7, 87, 111, 43, 313...  \n",
       "4   [2, 4, 1, 739, 183, 79, 43, 66, 312, 269, 75, ...  \n",
       "5   [2, 4, 1, 192, 2593, 176, 16, 1080, 96, 59, 67...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '2', '3', '4', '5', '6', '8', '9', '10', '11',\n",
       "       ...\n",
       "       '121647', '121648', '121649', '121650', '121652', '121653', '121655',\n",
       "       '121657', '121658', '121659'],\n",
       "      dtype='object', name='Id', length=87956)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AcceptedAnswerId                                                       NaN\n",
       "AnswerCount                                                            NaN\n",
       "Body                     &lt;p&gt;This is less than an answer, but more...\n",
       "ClosedDate                                                             NaN\n",
       "CommentCount                                                             1\n",
       "CommunityOwnedDate                                                     NaN\n",
       "CreationDate                                       2011-06-24T05:12:01.133\n",
       "FavoriteCount                                                          NaN\n",
       "Id                                                                     393\n",
       "LastActivityDate                                   2011-06-24T05:12:01.133\n",
       "LastEditDate                                                           NaN\n",
       "LastEditorDisplayName                                                  NaN\n",
       "LastEditorUserId                                                       NaN\n",
       "OwnerDisplayName                                                       NaN\n",
       "OwnerUserId                                                             74\n",
       "ParentId                                                                 1\n",
       "PostTypeId                                                               2\n",
       "Score                                                                    7\n",
       "Tags                                                                      \n",
       "Title                                                                     \n",
       "ViewCount                                                              NaN\n",
       "title_tokens                                                            []\n",
       "body_tokens              [2, 4, 1, 32, 14, 271, 88, 43, 216, 34, 74, 88...\n",
       "Name: 393, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['393']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473233, 552992)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts['a'], tokenizer.word_counts['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.603566009125561, 3.4478103418809867)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf['a'], idf['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177184"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'title': array([[  36,    6, 1403,  114,  277,  196,   10, 2615],\n",
       "         [  36,    6, 1403,  114,  277,  196,   10, 2615],\n",
       "         [  36,    6, 1403,  114,  277,  196,   10, 2615]], dtype=int32),\n",
       "  'body': array([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      2,\n",
       "               4,      1,     23,     12,    230,      6,    114,    277,\n",
       "              10,   1403,   2757,     18,      6,    685,      7,   2615,\n",
       "               9,    546,     39,     33,     12,    103,      5,    114,\n",
       "             277,      7,     56,    175,   2615,      2,      4,      1,\n",
       "               3,      3,      2,      4,      1,   1688,   2265,      7,\n",
       "          130123,   3522,     29,  25494,      2,      4,      1,      3],\n",
       "         [     2,      4,      1,     12,     82,     43,      2,     40,\n",
       "               1,  11106,    350,      2,     40,      1,      9,     12,\n",
       "              22,    142,   1120,      6,      2,     40,      1,   1378,\n",
       "             107,    135,     30,      2,     40,      1,    410,    135,\n",
       "             182,     15,     55,    409,     77,    137,     12,     36,\n",
       "              19,    283,      6,    659,    432,    398,    339,    106,\n",
       "              10,   1378,      2,      4,      1,      3,      3,      2,\n",
       "               4,      1,      5,    419,     14,     16,     12,     82,\n",
       "             279,     29,      2,     40,      1,   6555,      2,     40,\n",
       "               1,      7,      2,     40,      1,    292,      2,     40,\n",
       "               1,   1690,      9,     89,      7,      2,     40,      1,\n",
       "            1378,      2,     40,      1,     18,      5,    136,    114,\n",
       "            1604,     48,     12,     63,      6,    155,     30,     70,\n",
       "              12,    130,    292,      2,      4,      1,      3,      3,\n",
       "               2,      4,      1,      2,     40,      1,     37,     30,\n",
       "            2841,     16,     17,     14,     77,     15,   1378,    145],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      2,      4,      1,     12,     82,\n",
       "             279,      7,   1137,   7844,     15,     37,   3360,      9,\n",
       "              59,    656,     52,     37,    942,   1722,     10,    508,\n",
       "              16,     12,     54,     24,     19,    287,      7,    105,\n",
       "              37,  19459,     31,     96,     28,    342,     54,    105,\n",
       "              61,   5399,     24,     10,   2420,   2607,      2,      4,\n",
       "               1,      3,      3,      2,      4,      1,     12,     22,\n",
       "            2656,     15,      5,    342,    270,    816,     32,      9,\n",
       "              22,    423,     98,   1573,     18,     61,    439,    356,\n",
       "               5,  12034,      2,      6,     27,      8,     45, 101683,\n",
       "              44,     51,    161, 101684,      8,     38,      8,     46,\n",
       "               8,      1,   1137,   7844,  14378,    342,    780,      2,\n",
       "               6,      1,   5010,     73,  10555,    976,    202,  10719,\n",
       "               9,    308,   3859,   8025,      2,      4,      1,      3]],\n",
       "        dtype=int32)},\n",
       " array([1, 0, 0]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# We can create a data generator that will randomly title and body tokens for questions.  We'll use random text\n",
    "# from other questions as a negative example when necessary.\n",
    "def data_generator(batch_size, negative_samples=1):\n",
    "    questions = df[df['PostTypeId'] == 1]\n",
    "    all_q_ids = list(questions.index)\n",
    "        \n",
    "    batch_x_a = []\n",
    "    batch_x_b = []\n",
    "    batch_y = []\n",
    "    \n",
    "    def _add(x_a, x_b, y):\n",
    "        batch_x_a.append(x_a[:MAX_DOC_LEN])\n",
    "        batch_x_b.append(x_b[:MAX_DOC_LEN])\n",
    "        batch_y.append(y)\n",
    "    \n",
    "    while True:\n",
    "        questions = questions.sample(frac=1.0)\n",
    "        \n",
    "        for i, q in questions.iterrows():\n",
    "            _add(q['title_tokens'], q['body_tokens'], 1)\n",
    "            \n",
    "            negative_q = random.sample(all_q_ids, negative_samples)\n",
    "            for nq_id in negative_q:\n",
    "                _add(q['title_tokens'], df.at[nq_id, 'body_tokens'], 0)            \n",
    "            \n",
    "            if len(batch_y) >= batch_size:\n",
    "                yield ({\n",
    "                    'title': pad_sequences(batch_x_a, maxlen=None),\n",
    "                    'body': pad_sequences(batch_x_b, maxlen=None),\n",
    "                }, np.asarray(batch_y))\n",
    "                \n",
    "                batch_x_a = []\n",
    "                batch_x_b = []\n",
    "                batch_y = []\n",
    "\n",
    "dg = data_generator(1, 2)\n",
    "next(dg)\n",
    "next(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will a vancouver day pass work in victoria']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[36,    6, 1403,  114,  277,  196,   10, 2615]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"lt p gt if i buy a day pass in vancouver hop on a ferry to victoria and arrive there can i use the day pass to get around victoria lt p gt xa xa lt p gt we're heading to butchart gardens from burnaby lt p gt xa\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      0,\n",
    "               0,      0,      0,      0,      0,      0,      0,      2,\n",
    "               4,      1,     23,     12,    230,      6,    114,    277,\n",
    "              10,   1403,   2757,     18,      6,    685,      7,   2615,\n",
    "               9,    546,     39,     33,     12,    103,      5,    114,\n",
    "             277,      7,     56,    175,   2615,      2,      4,      1,\n",
    "               3,      3,      2,      4,      1,   1688,   2265,      7,\n",
    "          130123,   3522,     29,  25494,      2,      4,      1,      3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Lookups\n",
    "\n",
    "Let's define a helper class for looking up our embedding results.  We'll use it\n",
    "to verify our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[df['PostTypeId'] == 1]['Title'].reset_index(drop=True)\n",
    "question_tokens = pad_sequences(tokenizer.texts_to_sequences(questions))\n",
    "\n",
    "class EmbeddingWrapper(object):\n",
    "    def __init__(self, model):\n",
    "        self._r = questions\n",
    "        self._i = {i:s for (i, s) in enumerate(questions)}\n",
    "        self._w = model.predict({'title': question_tokens}, verbose=1, batch_size=1024)\n",
    "        self._model = model\n",
    "        self._norm = np.sqrt(np.sum(self._w * self._w + 1e-5, axis=1))\n",
    "\n",
    "    def nearest(self, sentence, n=10):\n",
    "        x = tokenizer.texts_to_sequences([sentence])\n",
    "        if len(x[0]) < MIN_DOC_LEN:\n",
    "            x[0] += [0] * (MIN_DOC_LEN - len(x))\n",
    "        e = self._model.predict(np.asarray(x))[0]\n",
    "        norm_e = np.sqrt(np.dot(e, e))\n",
    "        dist = np.dot(self._w, e) / (norm_e * self._norm)\n",
    "\n",
    "        top_idx = np.argsort(dist)[-n:]\n",
    "        return pd.DataFrame.from_records([\n",
    "            {'question': self._r[i], 'dist': float(dist[i])}\n",
    "            for i in top_idx\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first model will just sum up the embeddings of each token.\n",
    "# The similarity between documents will be the dot product of the final embedding.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def sum_model(embedding_size, vocab_size, embedding_weights=None, idf_weights=None):\n",
    "    title = layers.Input(shape=(None,), dtype='int32', name='title')\n",
    "    body = layers.Input(shape=(None,), dtype='int32', name='body')\n",
    "\n",
    "    def make_embedding(name):\n",
    "        if embedding_weights is not None:\n",
    "            embedding = layers.Embedding(mask_zero=True, input_dim=vocab_size, output_dim=w2v_weights.shape[1], \n",
    "                                         weights=[w2v_weights], trainable=False, \n",
    "                                         name='%s/embedding' % name)\n",
    "        else:\n",
    "            embedding = layers.Embedding(mask_zero=True, input_dim=vocab_size, output_dim=embedding_size,\n",
    "                                        name='%s/embedding' % name)\n",
    "\n",
    "        if idf_weights is not None:\n",
    "            idf = layers.Embedding(mask_zero=True, input_dim=vocab_size, output_dim=1, \n",
    "                                   weights=[idf_weights], trainable=False,\n",
    "                                   name='%s/idf' % name)\n",
    "        else:\n",
    "            idf = layers.Embedding(mask_zero=True, input_dim=vocab_size, output_dim=1,\n",
    "                                   name='%s/idf' % name)\n",
    "            \n",
    "        return embedding, idf\n",
    "    \n",
    "    embedding_a, idf_a = make_embedding('a')\n",
    "    embedding_b, idf_b = embedding_a, idf_a\n",
    "#     embedding_b, idf_b = make_embedding('b')\n",
    "\n",
    "    mask = layers.Masking(mask_value=0)\n",
    "    def _combine_and_sum(args):\n",
    "        [embedding, idf] = args\n",
    "        return K.sum(embedding * K.abs(idf), axis=1)\n",
    "\n",
    "    sum_layer = layers.Lambda(_combine_and_sum, name='combine_and_sum')\n",
    "\n",
    "    sum_a = sum_layer([mask(embedding_a(title)), idf_a(title)])\n",
    "    sum_b = sum_layer([mask(embedding_b(body)), idf_b(body)])\n",
    "\n",
    "    sim = layers.dot([sum_a, sum_b], axes=1, normalize=True)\n",
    "    sim_model = models.Model(\n",
    "        inputs=[title, body],\n",
    "        outputs=[sim],\n",
    "    )\n",
    "    sim_model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    sim_model.summary()\n",
    "\n",
    "    embedding_model = models.Model(\n",
    "        inputs=[title],\n",
    "        outputs=[sum_a]\n",
    "    )\n",
    "    return sim_model, embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a/embedding (Embedding)         (None, None, 100)    25000000    title[0][0]                      \n",
      "                                                                 body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 100)    0           a/embedding[0][0]                \n",
      "                                                                 a/embedding[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "a/idf (Embedding)               (None, None, 1)      250000      title[0][0]                      \n",
      "                                                                 body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "combine_and_sum (Lambda)        (None, 100)          0           masking_1[0][0]                  \n",
      "                                                                 a/idf[0][0]                      \n",
      "                                                                 masking_1[1][0]                  \n",
      "                                                                 a/idf[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           combine_and_sum[0][0]            \n",
      "                                                                 combine_and_sum[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 25,250,000\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,250,000\n",
      "__________________________________________________________________________________________________\n",
      "4096/4096 [==============================] - 0s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9652091963216662, 0.50927734375]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try using our model with pretrained weights from word2vec\n",
    "\n",
    "sum_model_precomputed, sum_embedding_precomputed = sum_model(\n",
    "    embedding_size=EMBEDDING_SIZE, vocab_size=VOCAB_SIZE,\n",
    "    embedding_weights=w2v_weights, idf_weights=idf_weights\n",
    ")\n",
    "\n",
    "x, y = next(data_generator(batch_size=4096))\n",
    "sum_model_precomputed.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31843/31843 [==============================] - 0s 3us/step\n",
      "Roundtrip ticket versus one way\n",
      "Shinkansen from Kyoto to Hiroshima\n",
      "Bus tour of Germany\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811505</td>\n",
       "      <td>Buy a roundtrip ticket for two people, but second person only travels on return - is that possible</td>\n",
       "      <td>Buy a roundtrip ticket for two people, but second person only travels on return - is that possible</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.813489</td>\n",
       "      <td>How to pick the (phony) return destination for a roundtrip ticket intended as a one-way?</td>\n",
       "      <td>How to pick the (phony) return destination for a roundtrip ticket intended as a one-way?</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815237</td>\n",
       "      <td>What is cheapest way to fly around SE Asia in a circuit - hub with roundtrip tickets or sequence...</td>\n",
       "      <td>What is cheapest way to fly around SE Asia in a circuit - hub with roundtrip tickets or sequence...</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.826175</td>\n",
       "      <td>The penalty for changing an airline ticket is per leg or per ticket?</td>\n",
       "      <td>The penalty for changing an airline ticket is per leg or per ticket?</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.753482</td>\n",
       "      <td>Culture Day in Osaka/Kyoto</td>\n",
       "      <td>Culture Day in Osaka/Kyoto</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756922</td>\n",
       "      <td>Where does the Tokaido Shinkansen stop in Tokyo?</td>\n",
       "      <td>Where does the Tokaido Shinkansen stop in Tokyo?</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.775683</td>\n",
       "      <td>Best connection Tokyo - Kyoto</td>\n",
       "      <td>Best connection Tokyo - Kyoto</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.812986</td>\n",
       "      <td>Travel from Tokyo to Sendai with Shinkansen</td>\n",
       "      <td>Travel from Tokyo to Sendai with Shinkansen</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891427</td>\n",
       "      <td>Trip in the south of Germany</td>\n",
       "      <td>Trip in the south of Germany</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895190</td>\n",
       "      <td>Travelling outside of Germany on a German Working Holiday visa (Australian)</td>\n",
       "      <td>Travelling outside of Germany on a German Working Holiday visa (Australian)</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.898518</td>\n",
       "      <td>Round trip in Netherlands, Belgium and Germany with a car and a tent</td>\n",
       "      <td>Round trip in Netherlands, Belgium and Germany with a car and a tent</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.902377</td>\n",
       "      <td>Transport for Tour of Southern Spain</td>\n",
       "      <td>Transport for Tour of Southern Spain</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dist  \\\n",
       "0  0.811505   \n",
       "1  0.813489   \n",
       "2  0.815237   \n",
       "3  0.826175   \n",
       "0  0.753482   \n",
       "1  0.756922   \n",
       "2  0.775683   \n",
       "3  0.812986   \n",
       "0  0.891427   \n",
       "1  0.895190   \n",
       "2  0.898518   \n",
       "3  0.902377   \n",
       "\n",
       "                                                                                              question  \\\n",
       "0   Buy a roundtrip ticket for two people, but second person only travels on return - is that possible   \n",
       "1             How to pick the (phony) return destination for a roundtrip ticket intended as a one-way?   \n",
       "2  What is cheapest way to fly around SE Asia in a circuit - hub with roundtrip tickets or sequence...   \n",
       "3                                 The penalty for changing an airline ticket is per leg or per ticket?   \n",
       "0                                                                           Culture Day in Osaka/Kyoto   \n",
       "1                                                     Where does the Tokaido Shinkansen stop in Tokyo?   \n",
       "2                                                                        Best connection Tokyo - Kyoto   \n",
       "3                                                          Travel from Tokyo to Sendai with Shinkansen   \n",
       "0                                                                         Trip in the south of Germany   \n",
       "1                          Travelling outside of Germany on a German Working Holiday visa (Australian)   \n",
       "2                                 Round trip in Netherlands, Belgium and Germany with a car and a tent   \n",
       "3                                                                 Transport for Tour of Southern Spain   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0   Buy a roundtrip ticket for two people, but second person only travels on return - is that possible   \n",
       "1             How to pick the (phony) return destination for a roundtrip ticket intended as a one-way?   \n",
       "2  What is cheapest way to fly around SE Asia in a circuit - hub with roundtrip tickets or sequence...   \n",
       "3                                 The penalty for changing an airline ticket is per leg or per ticket?   \n",
       "0                                                                           Culture Day in Osaka/Kyoto   \n",
       "1                                                     Where does the Tokaido Shinkansen stop in Tokyo?   \n",
       "2                                                                        Best connection Tokyo - Kyoto   \n",
       "3                                                          Travel from Tokyo to Sendai with Shinkansen   \n",
       "0                                                                         Trip in the south of Germany   \n",
       "1                          Travelling outside of Germany on a German Working Holiday visa (Australian)   \n",
       "2                                 Round trip in Netherlands, Belgium and Germany with a car and a tent   \n",
       "3                                                                 Transport for Tour of Southern Spain   \n",
       "\n",
       "                                 body  \n",
       "0     Roundtrip ticket versus one way  \n",
       "1     Roundtrip ticket versus one way  \n",
       "2     Roundtrip ticket versus one way  \n",
       "3     Roundtrip ticket versus one way  \n",
       "0  Shinkansen from Kyoto to Hiroshima  \n",
       "1  Shinkansen from Kyoto to Hiroshima  \n",
       "2  Shinkansen from Kyoto to Hiroshima  \n",
       "3  Shinkansen from Kyoto to Hiroshima  \n",
       "0                 Bus tour of Germany  \n",
       "1                 Bus tour of Germany  \n",
       "2                 Bus tour of Germany  \n",
       "3                 Bus tour of Germany  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_QUESTIONS = [\n",
    "    'Roundtrip ticket versus one way',\n",
    "    'Shinkansen from Kyoto to Hiroshima',\n",
    "    'Bus tour of Germany',\n",
    "]\n",
    "\n",
    "def evaluate_sample(lookup):\n",
    "    pd.set_option('display.max_colwidth', 100)\n",
    "    results = []\n",
    "    for q in SAMPLE_QUESTIONS:\n",
    "        print(q)\n",
    "        q_res = lookup.nearest(q, n=4)\n",
    "        q_res['title'] = q_res['question']\n",
    "        q_res['body'] = q\n",
    "        results.append(q_res)\n",
    "\n",
    "    return pd.concat(results)\n",
    "\n",
    "lookup = EmbeddingWrapper(model=sum_embedding_precomputed)\n",
    "evaluate_sample(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own network\n",
    "\n",
    "The results are okay but not great... instead of using the word2vec embeddings, what happens if we train our network end-to-end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a/embedding (Embedding)         (None, None, 100)    25000000    title[0][0]                      \n",
      "                                                                 body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 100)    0           a/embedding[0][0]                \n",
      "                                                                 a/embedding[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "a/idf (Embedding)               (None, None, 1)      250000      title[0][0]                      \n",
      "                                                                 body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "combine_and_sum (Lambda)        (None, 100)          0           masking_2[0][0]                  \n",
      "                                                                 a/idf[0][0]                      \n",
      "                                                                 masking_2[1][0]                  \n",
      "                                                                 a/idf[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           combine_and_sum[0][0]            \n",
      "                                                                 combine_and_sum[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 25,250,000\n",
      "Trainable params: 25,250,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2596 - acc: 0.9235\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1457 - acc: 0.9770\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1157 - acc: 0.9844\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1027 - acc: 0.9873\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0943 - acc: 0.9890\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0889 - acc: 0.9898\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0858 - acc: 0.9904\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0814 - acc: 0.9909\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0776 - acc: 0.9921\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0751 - acc: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8afcd9d240>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_model_trained, sum_embedding_trained = sum_model(\n",
    "    embedding_size=EMBEDDING_SIZE, vocab_size=VOCAB_SIZE, \n",
    "    embedding_weights=None,\n",
    "    idf_weights=None\n",
    ")\n",
    "sum_model_trained.fit_generator(\n",
    "    data_generator(batch_size=128),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31843/31843 [==============================] - 0s 3us/step\n",
      "Roundtrip ticket versus one way\n",
      "Shinkansen from Kyoto to Hiroshima\n",
      "Bus tour of Germany\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>question</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769217</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>How to get return prices for a one way ticket?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770204</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>How do one way/round trip plane tickets work?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.773594</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>Can I buy another set of round trip tickets if I already have one for a later date?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793570</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>Buy a roundtrip ticket for two people, but second person only travels on return - is that possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959197</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>What does my Shinkansen ticket say?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959941</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>Hokkaido Shinkansen - Sendai with JR Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961790</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>Stopovers on Shinkansen services?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.963612</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>What are my options for reserving JR Shinkansen tickets in advance over the new year period?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.622985</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>About inter-city and inter-country bus services in Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.625273</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>European bus tour companies for middle age people?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.656673</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>How to find inter-country buses in Europe?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.710560</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>Searching for internal bus connections in Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dist                            question  \\\n",
       "0  0.769217     Roundtrip ticket versus one way   \n",
       "1  0.770204     Roundtrip ticket versus one way   \n",
       "2  0.773594     Roundtrip ticket versus one way   \n",
       "3  0.793570     Roundtrip ticket versus one way   \n",
       "0  0.959197  Shinkansen from Kyoto to Hiroshima   \n",
       "1  0.959941  Shinkansen from Kyoto to Hiroshima   \n",
       "2  0.961790  Shinkansen from Kyoto to Hiroshima   \n",
       "3  0.963612  Shinkansen from Kyoto to Hiroshima   \n",
       "0  0.622985                 Bus tour of Germany   \n",
       "1  0.625273                 Bus tour of Germany   \n",
       "2  0.656673                 Bus tour of Germany   \n",
       "3  0.710560                 Bus tour of Germany   \n",
       "\n",
       "                                                                                               result  \n",
       "0                                                      How to get return prices for a one way ticket?  \n",
       "1                                                       How do one way/round trip plane tickets work?  \n",
       "2                 Can I buy another set of round trip tickets if I already have one for a later date?  \n",
       "3  Buy a roundtrip ticket for two people, but second person only travels on return - is that possible  \n",
       "0                                                                 What does my Shinkansen ticket say?  \n",
       "1                                                           Hokkaido Shinkansen - Sendai with JR Pass  \n",
       "2                                                                   Stopovers on Shinkansen services?  \n",
       "3        What are my options for reserving JR Shinkansen tickets in advance over the new year period?  \n",
       "0                                           About inter-city and inter-country bus services in Europe  \n",
       "1                                                  European bus tour companies for middle age people?  \n",
       "2                                                          How to find inter-country buses in Europe?  \n",
       "3                                                   Searching for internal bus connections in Germany  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = EmbeddingWrapper(model=sum_embedding_trained)\n",
    "evaluate_sample(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "Using a sum-of-embeddings model works well. What happens if we try to make a simple CNN model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(embedding_size, vocab_size):\n",
    "    title = layers.Input(shape=(None,), dtype='int32', name='title')\n",
    "    body = layers.Input(shape=(None,), dtype='int32', name='body')\n",
    "\n",
    "    embedding = layers.Embedding(\n",
    "        mask_zero=False,\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_size,\n",
    "    )\n",
    "\n",
    "\n",
    "    def _combine_sum(v):\n",
    "        return K.sum(v, axis=1)\n",
    "\n",
    "    cnn_1 = layers.Convolution1D(256, 3)\n",
    "    cnn_2 = layers.Convolution1D(256, 3)\n",
    "    cnn_3 = layers.Convolution1D(256, 3)\n",
    "    \n",
    "    global_pool = layers.GlobalMaxPooling1D()\n",
    "    local_pool = layers.MaxPooling1D(strides=2, pool_size=3)\n",
    "\n",
    "    def forward(input):\n",
    "        embed = embedding(input)\n",
    "        return global_pool(\n",
    "            cnn_2(local_pool(cnn_1(embed))))\n",
    "\n",
    "    sum_a = forward(title)\n",
    "    sum_b = forward(body)\n",
    "\n",
    "    sim = layers.dot([sum_a, sum_b], axes=1, normalize=False)\n",
    "    sim_model = models.Model(\n",
    "        inputs=[title, body],\n",
    "        outputs=[sim],\n",
    "    )\n",
    "    sim_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    embedding_model = models.Model(\n",
    "        inputs=[title],\n",
    "        outputs=[sum_a]\n",
    "    )\n",
    "    return sim_model, embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 25)     6250000     title[0][0]                      \n",
      "                                                                 body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    19456       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    196864      max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 1)            0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_1[1][0]     \n",
      "==================================================================================================\n",
      "Total params: 6,466,320\n",
      "Trainable params: 6,466,320\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6393 - acc: 0.6477\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5735 - acc: 0.7489\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5489 - acc: 0.7755\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5346 - acc: 0.7715\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5141 - acc: 0.7650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5111 - acc: 0.7456\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5072 - acc: 0.7002\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5536 - acc: 0.6730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5229 - acc: 0.6391\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5647 - acc: 0.5890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b0437af28>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn, cnn_embedding = cnn_model(embedding_size=25, vocab_size=VOCAB_SIZE)\n",
    "cnn.summary()\n",
    "cnn.fit_generator(\n",
    "    data_generator(batch_size=128),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31843/31843 [==============================] - 0s 13us/step\n",
      "Roundtrip ticket versus one way\n",
      "Shinkansen from Kyoto to Hiroshima\n",
      "Bus tour of Germany\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>question</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945426</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>Dalhousie to Udawalawe?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945605</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>religious problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946507</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>Mugging 'Etiquette'?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.946684</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "      <td>On short connections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987494</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>Newbie Traveler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987831</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>Tegelbergbahn Tickets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.987883</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>Mugging 'Etiquette'?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988238</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "      <td>Nagorno-Karabakh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926533</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>Schengeni Allamok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926621</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>Newbie Traveler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.926886</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>Unmatching Barcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.928118</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "      <td>Nagorno-Karabakh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dist                            question                   result\n",
       "0  0.945426     Roundtrip ticket versus one way  Dalhousie to Udawalawe?\n",
       "1  0.945605     Roundtrip ticket versus one way        religious problem\n",
       "2  0.946507     Roundtrip ticket versus one way     Mugging 'Etiquette'?\n",
       "3  0.946684     Roundtrip ticket versus one way     On short connections\n",
       "0  0.987494  Shinkansen from Kyoto to Hiroshima          Newbie Traveler\n",
       "1  0.987831  Shinkansen from Kyoto to Hiroshima    Tegelbergbahn Tickets\n",
       "2  0.987883  Shinkansen from Kyoto to Hiroshima     Mugging 'Etiquette'?\n",
       "3  0.988238  Shinkansen from Kyoto to Hiroshima         Nagorno-Karabakh\n",
       "0  0.926533                 Bus tour of Germany        Schengeni Allamok\n",
       "1  0.926621                 Bus tour of Germany          Newbie Traveler\n",
       "2  0.926886                 Bus tour of Germany       Unmatching Barcode\n",
       "3  0.928118                 Bus tour of Germany         Nagorno-Karabakh"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = EmbeddingWrapper(model=cnn_embedding)\n",
    "evaluate_sample(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model\n",
    "\n",
    "We can also make an LSTM model.  Warning, this will be very slow to train and evaluate unless you have a relatively fast GPU to run it on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(embedding_size, vocab_size):\n",
    "    title = layers.Input(shape=(None,), dtype='int32', name='title')\n",
    "    body = layers.Input(shape=(None,), dtype='int32', name='body')\n",
    "\n",
    "    embedding = layers.Embedding(\n",
    "        mask_zero=True,\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_size,\n",
    "#         weights=[w2v_weights],\n",
    "#         trainable=False\n",
    "    )\n",
    "\n",
    "    lstm_1 = layers.LSTM(units=512, return_sequences=True)\n",
    "    lstm_2 = layers.LSTM(units=512, return_sequences=False)\n",
    "    \n",
    "    sum_a = lstm_2(lstm_1(embedding(title)))\n",
    "    sum_b = lstm_2(lstm_1(embedding(body)))\n",
    "\n",
    "    sim = layers.dot([sum_a, sum_b], axes=1, normalize=True)\n",
    "#     sim = layers.Activation(activation='sigmoid')(sim)\n",
    "    sim_model = models.Model(\n",
    "        inputs=[title, body],\n",
    "        outputs=[sim],\n",
    "    )\n",
    "    sim_model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    embedding_model = models.Model(\n",
    "        inputs=[title],\n",
    "        outputs=[sum_a]\n",
    "    )\n",
    "    return sim_model, embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    25000000    title[0][0]                      \n",
      "                                                                 body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 512)    1255424     embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 512)          2099200     lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 1)            0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 28,354,624\n",
      "Trainable params: 28,354,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.8197\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 92s 917ms/step - loss: 0.7351\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 93s 926ms/step - loss: 0.7100\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 92s 915ms/step - loss: 0.7308\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 0.7948\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 91s 915ms/step - loss: 0.7098\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 92s 920ms/step - loss: 0.7013\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 92s 917ms/step - loss: 0.7529\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 93s 927ms/step - loss: 0.6975\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 92s 917ms/step - loss: 0.6965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8af06f9a20>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm, lstm_embedding = lstm_model(embedding_size=EMBEDDING_SIZE, vocab_size=VOCAB_SIZE)\n",
    "lstm.summary()\n",
    "lstm.fit_generator(\n",
    "    data_generator(batch_size=128),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31843/31843 [==============================] - 7s 208us/step\n",
      "Roundtrip ticket versus one way\n",
      "Shinkansen from Kyoto to Hiroshima\n",
      "Bus tour of Germany\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997782</td>\n",
       "      <td>Getting a BART clipper card</td>\n",
       "      <td>Getting a BART clipper card</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997786</td>\n",
       "      <td>Strange ZIP codes in Alaska?</td>\n",
       "      <td>Strange ZIP codes in Alaska?</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997941</td>\n",
       "      <td>Volunteering for an archaeological dig</td>\n",
       "      <td>Volunteering for an archaeological dig</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998024</td>\n",
       "      <td>Getting to Barrow, Alaska overland</td>\n",
       "      <td>Getting to Barrow, Alaska overland</td>\n",
       "      <td>Roundtrip ticket versus one way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998042</td>\n",
       "      <td>Halifax long layover, recheck bags?</td>\n",
       "      <td>Halifax long layover, recheck bags?</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998094</td>\n",
       "      <td>Renting camping equipment in Nambia</td>\n",
       "      <td>Renting camping equipment in Nambia</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998123</td>\n",
       "      <td>Luggage storage in Tulum, Mexico?</td>\n",
       "      <td>Luggage storage in Tulum, Mexico?</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998173</td>\n",
       "      <td>Bandipur national park opening dates?</td>\n",
       "      <td>Bandipur national park opening dates?</td>\n",
       "      <td>Shinkansen from Kyoto to Hiroshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994282</td>\n",
       "      <td>Other agencies for passport</td>\n",
       "      <td>Other agencies for passport</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994292</td>\n",
       "      <td>Extension of Schengen Visa</td>\n",
       "      <td>Extension of Schengen Visa</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994323</td>\n",
       "      <td>Possible Overlapping Schengen Visas</td>\n",
       "      <td>Possible Overlapping Schengen Visas</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994433</td>\n",
       "      <td>Stamps of passport gone</td>\n",
       "      <td>Stamps of passport gone</td>\n",
       "      <td>Bus tour of Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dist                                question  \\\n",
       "0  0.997782             Getting a BART clipper card   \n",
       "1  0.997786            Strange ZIP codes in Alaska?   \n",
       "2  0.997941  Volunteering for an archaeological dig   \n",
       "3  0.998024      Getting to Barrow, Alaska overland   \n",
       "0  0.998042     Halifax long layover, recheck bags?   \n",
       "1  0.998094     Renting camping equipment in Nambia   \n",
       "2  0.998123       Luggage storage in Tulum, Mexico?   \n",
       "3  0.998173   Bandipur national park opening dates?   \n",
       "0  0.994282             Other agencies for passport   \n",
       "1  0.994292              Extension of Schengen Visa   \n",
       "2  0.994323     Possible Overlapping Schengen Visas   \n",
       "3  0.994433                 Stamps of passport gone   \n",
       "\n",
       "                                    title                                body  \n",
       "0             Getting a BART clipper card     Roundtrip ticket versus one way  \n",
       "1            Strange ZIP codes in Alaska?     Roundtrip ticket versus one way  \n",
       "2  Volunteering for an archaeological dig     Roundtrip ticket versus one way  \n",
       "3      Getting to Barrow, Alaska overland     Roundtrip ticket versus one way  \n",
       "0     Halifax long layover, recheck bags?  Shinkansen from Kyoto to Hiroshima  \n",
       "1     Renting camping equipment in Nambia  Shinkansen from Kyoto to Hiroshima  \n",
       "2       Luggage storage in Tulum, Mexico?  Shinkansen from Kyoto to Hiroshima  \n",
       "3   Bandipur national park opening dates?  Shinkansen from Kyoto to Hiroshima  \n",
       "0             Other agencies for passport                 Bus tour of Germany  \n",
       "1              Extension of Schengen Visa                 Bus tour of Germany  \n",
       "2     Possible Overlapping Schengen Visas                 Bus tour of Germany  \n",
       "3                 Stamps of passport gone                 Bus tour of Germany  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = EmbeddingWrapper(model=lstm_embedding)\n",
    "evaluate_sample(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
